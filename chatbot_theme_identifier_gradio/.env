# chatbot_theme_identifier_gradio/.env
# Example overrides for local development

# LLM_PROVIDER="local_llama_server" # Defaulted in settings.py
# LOCAL_LLM_API_BASE_URL="http://localhost:8080/v1" # Ensure your llama.cpp server runs here
# LOCAL_LLM_MODEL_NAME="your-model.gguf" # Or model ID for Ollama

# EMBEDDING_PROVIDER="local_hf" # Defaulted in settings.py
# LOCAL_HF_EMBEDDING_MODEL_NAME="all-MiniLM-L6-v2"

# To use OpenAI for LLM (example):
# LLM_PROVIDER="openai_api"
# OPENAI_API_KEY="sk-yourActualOpenAIKeyHere"
# OPENAI_LLM_MODEL_NAME="gpt-4o-mini" # Or another model

# To use OpenAI for Embeddings (example):
# EMBEDDING_PROVIDER="openai_api"
# OPENAI_EMBEDDING_API_KEY="sk-yourActualOpenAIKeyHere" # Can be same as above
# OPENAI_EMBEDDING_MODEL_NAME="text-embedding-3-small"

# GRADIO_SHARE=False